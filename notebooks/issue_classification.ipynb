{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue Classification Example\n",
    "\n",
    "In this example we perform a logical regression on a dataset of github issues to predict the labels on newly entered tickets.\n",
    "\n",
    "In a second step we try to find issues that deal with similar problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required libraries\n",
    "from github import Github\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# we are using some less optimal code, suppress the warnings for now\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "TODO: In the final stage, we need to make sure that we keep track of the unique labels and how they are represented in the NN (by index or otherwise). Changes to the set (labels added/removed) need to be anticipated. This can happen when issues arrive that we haven't seen before and that include labels that have been unknown at training time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve issues from github\n",
    "\n",
    "force_fetch = False\n",
    "\n",
    "access_token = USER = os.getenv('GH_API_ACCESS')\n",
    "token = Github(access_token)\n",
    "repo = token.get_repo('quarkusio/quarkus')\n",
    "\n",
    "# load issue if they don't exist (or forced)\n",
    "if (force_fetch or not os.path.exists('../data/issues.pkl')): \n",
    "    issues = repo.get_issues(state='open')  \n",
    "    \n",
    "    cols = columns = ['number', 'title', 'body', 'labels', 'state']\n",
    "    df = pd.DataFrame(columns = cols)\n",
    "    unique_labels = set()\n",
    "\n",
    "    for issue in issues:    \n",
    "        label_names = []\n",
    "        for label in issue.labels:        \n",
    "            label_names.append(label.name)\n",
    "            if not label.name.startswith(\"triage\"): # this clause is specific to the underlying data of this specific repo\n",
    "                unique_labels.add(label.name)\n",
    "        new_record = pd.DataFrame([[issue.number, issue.title, issue.body, label_names, issue.state]], columns=cols)\n",
    "        df = pd.concat([df, new_record], ignore_index=True)    \n",
    "\n",
    "    pickle.dump(df, open('../data/issues.pkl', 'wb'))\n",
    "    pickle.dump(unique_labels, open('../data/labels.pkl', 'wb'))\n",
    "else:\n",
    "    print(\"Loading issues from file...\")\n",
    "    unique_labels = pickle.load(open(\"../data/labels.pkl\", 'rb'))\n",
    "    df = pickle.load(open(\"../data/issues.pkl\", 'rb'))\n",
    "\n",
    "# let's see what we have\n",
    "print(\"Number of issues in total: \", len(df))\n",
    "print(\"Unique labels ({0})\".format(len(unique_labels)))    \n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the raw data, we need to prepare project the dependentant variables (labels) into the DF and tackle the tokenization of the text (title, body) \n",
    "\n",
    "Let's start with the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project the keys of the known labels\n",
    "for key in unique_labels:\n",
    "    df.insert(len(df.columns), key, 0)\n",
    "\n",
    "# # project the values of the of actual labels used on each issue\n",
    "for index, row in df.iterrows():    \n",
    "    if isinstance(row[\"labels\"], list): # omit empty labels        \n",
    "        for label_used in row[\"labels\"]:\n",
    "            if label_used in unique_labels:\n",
    "                df.loc[index, [label_used]] = 1                        \n",
    "                        \n",
    "df.head()\n",
    "\n",
    "# let's what we got\n",
    "first_label = next(iter(unique_labels))\n",
    "df[first_label].value_counts().plot(kind='pie', )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
